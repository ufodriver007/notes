
#### Полносвязанная нейронная сеть прямого распространения
- Сеть прямого распространения не имеет обратных связей
- Нейронная сеть состоит из слоёв. Есть ВХОДНОЙ слой, точки, куда поступают данные. И эти
точки соединяются связями со следующими слоями. Далее идут СКРЫТЫЕ слои. Где каждый нейрон слоя соединяется с каждым нейроном последующего слоя. И наконец последний ВЫХОДНОЙ слой.
- Каждая связь имеет свой вес(w - омега). 
- В нейроне вес каждой связи перемножается на её сигнал и складываются между собой. Затем
 получившееся значение попадает в функцию активации и результат отправляется дальше.

![[2024-01-07_20-48.png]]

```python
import numpy as np


# Функция сигмоида
# Необходима для определения значения весов в опред. диапазоне
def sigmoid(x, der=False):
    if der:
        return x * (1 - x)
    return 1 / (1 + np.exp(-x))

# входные данные
x = np.array([[1, 0, 1],
              [1, 0, 1],
              [0, 1, 0],
              [0, 1, 0]])

# выходные(ожидаемые) данные. функция переноса
y = np.array([[0, 0, 1, 1]]).T

# чтобы случайное распределение было одним и тем же каждый раз
np.random.seed(1)

# Инициализируем веса случайным образом со средним 0
syn0 = 2 * np.random.random((3, 1)) - 1

l1 = []

for iter in range(10000):
    # Прямое распространение
    l0 = x
    l1 = sigmoid(np.dot(l0, syn0))

    # Насколько мы ошиблись
    l1_error = y - l1

    # Перемножим это с наклоном сигмоиды
    # на основе значений в l1
    l1_delta = l1_error * sigmoid(l1, True)

    # Обновим веса
    syn0 += np.dot(l0.T, l1_delta)

print("Выходные данные после тренировки:")
print(l1)

new_one = np.array([1, 0, 1])
l1_new = sigmoid(np.dot(new_one, syn0))
print("Новые данные:")
print(l1_new)
```