
#### Деплой телеграм бота
###### Подготовим сервер
```bash
sudo apt-get install -y htop curl wget tmux mc git
apt update && apt upgrade
useradd -m -s /bin/bash -G sudo mike
passwd mike
```

```bash
apt install ufw
sudo ufw status verbose
ufw app list
ufw allow ssh
ufw enable
```

###### SSH-ключи
добавить ssh-ключ на сервер(делаем это на др. машине)
```bash
ssh-keygen -t rsa                   создаём ключ (на др. машине)
cat ~/.ssh/id_rsa.pub               сам ключ (на др. машине)
ssh-copy-id root@123.123.123.123    копируем ключ на сервер (с др. машины)
```

```
/home/username/.ssh/authorized_keys          место хранения авторизированных публичных SSH-ключей
ssh -i <путь до приватного ключа> username@server IP   авторизация по ключу. Чтобы каждый раз не
                                                       указывать путь, достаточно скопировать
                                             закрытый ключ в папку /home/имя пользователя/.ssh
```

логинимся и копируем ssh ключи рута в директорию нового пользователя
```bash
su - mike
mkdir /home/mike/.ssh/
sudo cp -r /root/.ssh/authorized_keys /home/mike/.ssh/authorized_keys
sudo chown mike /home/mike/.ssh/authorized_keys
```

>[!warning] ПЕРЕД ЗАПРЕТОМ ЛОГИНА ПОД root, ПРОВЕРЯЕМ ДОСТУП ПО SSH
```bash
sudo nano /etc/ssh/sshd_config
```

```
AllowUsers myuser
PermitRootLogin yes меняем на no
PasswordAuthentication yes меняем на no
```
```bash
sudo service ssh restart
```

###### ПЕРЕМЕННЫЕ ОКРУЖЕНИЯ
Хранить данные в переменной окружения. Задать переменную в Linux для текущего сеанса оболчки `export PASSWORD=12345` (или же добавить эту строчку в `~/.bashrc`)
Или копируем `.env` от себя на сервер:
```bash
scp /<путь_к_папке_с_файлом_.env>/.env mike@188.124.51.136:/home/mike/FSM_example_bot
```

###### Git
клонируем нужный репозиторий


создаём окружение
```bash
python3 -m venv venv
```

Активируем виртуальное окружение
```bash
source venv/bin/activate
```

Убеждаемся, что мы в виртуальном окружении. Ставим pip
```bash
sudo apt install python3-pip
```

устанавливаем зависимости
```bash
pip install -r pip_req.txt
```


###### Создание юнита в Systemd и запуск демона

Переходим в директорию с юнитами Systemd
```bash
cd /etc/systemd/system/
```

Создаём юнит
```bash
sudo nano FSM_example_bot.service
```

Пишем туда
```
[Unit]
Description=FSM_example_bot
After=syslog.target       # ещё вариант After=multi-user.target (многопользов. режим без графики)
After=network.target

[Service]
Type=simple
User=mike
WorkingDirectory=/home/mike/FSM_example_bot
ExecStart=/home/mike/FSM_example_bot/venv/bin/python3 /home/mike/FSM_example_bot/bot.py
Restart=always
TimeoutStopSec=10
KillMode=process

[Install]
WantedBy=multi-user.target
```

Заново читаем конфигурацию Systemd
```bash
sudo systemctl daemon-reload
```

запускаем только что созданный юнит
```bash
sudo systemctl enable FSM_example_bot
sudo systemctl start FSM_example_bot
```

Если что:
```bash
sudo systemctl status FSM_example_bot
```

перезапуск вручную
```bash
sudo systemctl restart FSM_example_bot
```

остановить юнит
```bash
sudo systemctl stop FSM_example_bot
```

Если надо апдейтнуть бота:

```bash
git pull
sudo systemctl restart FSM_example_bot
```

###### Передача файлов по ssh
```bash
scp ~/file.txt root@192.168.0.101:/root           передача одного файла
scp -r ~/files root@192.168.0.101:/root           передача папки рекурсивно
```

#### Деплой Django проекта
![[deploy.png]]
>[!info] https://www.digitalocean.com/community/tutorials/how-to-set-up-django-with-postgres-nginx-and-gunicorn-on-ubuntu-22-04

###### Первоначальная настройка
- Нужно создать пользователя
 ```bash
adduser user_name
```
- Пользователь должен быть добавлен в группы
 ```bash
usermod -aG sudo user_name
usermod -aG www-data user_name
```
- Переключаемся на нашего пользователя:
 ```bash
su - user_name
```
- Переходим в папку нового пользователя и клонируем туда репозиторий
- Создаём виртуальное окружение и активируем его
- Устанавливаем зависимости проекта
- Применяем миграции
 ```bash
python3 manage.py migrate
```
- Собираем статику
 ```bash
python3 manage.py collectstatic
```
- Пробуем запустить проект через `runserver`
 ```bash
sudo ufw allow 8000
python3 manage.py runserver 0.0.0.0:8000
```
- Если сайт открывается по адресу `http://<ip_нашего_сервера>:8000`, то идём дальше

###### Установка и настройка Gunicorn
- Устанавливаем gunicorn
```bash
pip install gunicorn
```
- Чтобы проверить возможность gunicorn работать(из `venv` из дирескотрии где `manage.py`):
```bash
gunicorn --bind 0.0.0.0:8000 <my_project>.wsgi
```
- Переключаемся на root, чтобы создать юнит для gunicorn
```bash
nano /etc/systemd/system/project_name.gunicorn.service
```

```
[Unit]
Description=gunicorn daemon
After=network.target

[Service]
User=<linux user>
Group=www-data
WorkingDirectory=<project_root_directory>
ExecStart=<project_root_directory>/venv/bin/gunicorn --access-logfile - --workers 3 --bind unix:<project_root_directory>server.sock <Project main application>.wsgi:application

[Install]
WantedBy=multi-user.target
```

Где:
`<project_root_directory>` - путь до вашего проекта, например: `/home/my_user/my_project/`.
`<Project main application>` - название главного приложения (где лежат главные `urls.py`, `settings.py` и сам `.wsgi` файл.

 >[!info] Количество ворекров = 2 * кол-во ядер + 1
 
- Включаем юнит и запускаем демона
 ```bash
sudo systemctl enable <project_name>.gunicorn
sudo systemctl start <project_name>.gunicorn
```
- Проверяем запущен ли демон
```bash
sudo systemctl status <project_name>.gunicorn
```
- Проверяем наличие файла `sock`(это означает, что gunicorn работает штатно) в директории проекта(файл `sock` - место обмена данными между двумя программами, в данном случае: gunicorn и nginx. Он используется вместо взаимодействия по TCP протоколу, т.к. нужно обмениваться данными не по сети, а на одном компьютере, в одной ОС. Такое взаимодейсвтие гораздо легче для ОС.)
- Если файла sock нет, значит gunicorn не смог нормально запуститься. Проверьте журнал
```bash
sudo journalctl -u gunicorn
```
 
 Если редактируем этот конфиг сервиса, чтобы изменения вступили в силу:
```bash
sudo systemctl daemon-reload
sudo systemctl restart gunicorn
```

###### Установка и настройка Nginx как прокси для Guincorn
По сути пробрасывает запросы извне в файл сокета gunicorn
- Устанавливаем Nginx
 ```bash
sudo apt install nginx
```
- Настраиваем Nginx для передачи трафика процессу. Создаём файл
```bash
sudo nano /etc/nginx/sites-available/<project_name>
```

```
    server {
    listen 80;
    server_name <server_ip or domain_name>;

    location = /favicon.ico { access_log off; log_not_found off; }
    location /static/ {
    root <project_root_directory> ;
    }

    location / {
    include proxy_params;
    proxy_pass http://unix:<путь_к_sock_файлу>;
    }
    }
```

 В блоке указано, что nginx должен прослушивать порт 80 и отвечать на доменное имя или IP-адрес сервера.
  Далее указано игнорировать любые  проблемы с поиском значка и путь до статических ресурсов. Последний блок location / {} соответствует всем другим запросам.
- Создаем символическую ссылку
```bash
sudo ln -s /etc/nginx/sites-available/<project_name> /etc/nginx/sites-enabled/<project_name>
```
- Далее необходимо проверить конфигурацию Nginx на наличие синтаксических ошибок
```bash
sudo nginx -t
```
- Если ошибки не найдены, перезапустите Nginx
```bash
sudo systemctl restart nginx
   # или
sudo nginx -s reload
```
- Наконец, нужно открыть брандмауэр для нормального трафика через порт 80. Поскольку доступ к серверу разработки больше не нужен, нужно удалить правило, которое открывает порт 8000
```bash
sudo ufw delete allow 8000
sudo ufw allow 'Nginx Full'
```

Логи nginx можно посмотреть здесь `/var/log/nginx/error.log`
Если в логах `(13: Permission denied) while connecting to upstream`, то nginx пользователю нужны права для доступа к файлу sock. Это можно решить добавив пользователем root. В файле `/etc/nginx/nginx.conf` ставим `user root;`

###### Использование supervisor
Это простой менеджер процессов с открытым исходным кодом, написанный на Python, с помощью которого можно запускать нужное количество копий процесса и следить за их состоянием

```bash
sudo apt-get install supervisor
sudo systemctl enable supervisor --now
sudo systemctl status supervisor
```

```bash
sudo nano /etc/supervisor/conf.d/project1.conf
```

В этом файле пишем:
```
[program:gunicorn]
command=/home/www/code/project1/bin/start_gunicorn.sh
user=www
process_name=%(program_name)s
numproc=1
autostart=1
autorestart=1
redirect_stderr=true
```


```bash
sudo service supervisor start
sudo nano /var/log/supervisor
```

Статус всех отслеживаемых процессов
```bash
sudo supervisorctl status
```


###### SSL-сертификат
Сертификат от certbot на 3 месяца

```bash
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx
```
Далее вводим свой email(для напоминания об истекающем сроке действия) и выбираем домен.
Certbot сам исправит конфиг nginx и поставит редиректы.

###### Подтянуть актуальную версию на продакшн:
```bash
cd /home/ufodriver/mint-coast-project/mint-coast
git pull
sudo systemctl restart mint_coast.gunicorn
```

#### Деплой Django проекта с помощью Docker
![[Pasted image 20240215055352.png]]
>[!info] Деплой Django проекта используя Docker, Nginx, PostgreSQL, Gunicorn и certbot

###### Подготовка Django проекта к деплою
1. должен быть создан `.env` файл
2. DEBUG=False
Соответственно `ALLOWED_HOSTS = ['*']` и нужно определить `STATIC_ROOT`. Можно использовать такую конструкцию
```python
if DEBUG:  
    STATICFILES_DIRS = [  
        os.path.join(BASE_DIR, 'static')  
    ]  
else:  
    STATIC_ROOT = os.path.join(BASE_DIR, STATIC_URL)
```
3. Должны быть корректно указаны данные для БД
```python
DATABASES = {  
    'default': {  
        'ENGINE': 'django.db.backends.postgresql',  
        'NAME': os.environ.get('POSTGRES_DB'),  
        'USER': os.environ.get('POSTGRES_USER'),  
        'PASSWORD': os.environ.get('POSTGRES_PASSWORD'),  
        'HOST': 'db',                   # имя сервиса в docker-compose.yml
        'PORT': 5432,                   
    }  
}
```
4. `requirments.txt` должен содержать актуальные зависимости

###### Делаем образ Django проекта
Предположим у нас есть готовый Django проект `hello_world`. Сначала создаём `Dockerfile` (рядом с `manage.py`)
```docker
FROM python:3.11

ENV PYTHONDONTWRITEBYTECODE=1 
ENV PYTHONUNBUFFERED=1 

WORKDIR /code 

RUN pip install --upgrade pip 
RUN apt update && apt -y install curl

COPY . /code/

RUN pip install -r requirements.txt

CMD python manage.py migrate \
        && python manage.py shell -c "from django.contrib.auth import get_user_model; User = get_user_model(); User.objects.filter(username='root').exists() or User.objects.create_superuser('root', 'root@example.com', 'root')" \
        && python manage.py collectstatic --no-input \
        && gunicorn hello_world.wsgi:application --bind 0.0.0.0:8000 --log-level info
```

###### Создаём конфиг для NGINX
Для начала нужно иметь файлы конфигурации nginx для нашего сайта. Создаём папку `nginx` и в ней `nginx.conf`. Пример `nginx.conf`, где вся статика отдаётся сервером nginx и соответственно облегчает выполнение Python кода.
```
events {}

http {
    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://hello_world:8000;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Host $host;
            proxy_redirect off;
            if (!-f $request_filename) {
                proxy_pass http://hello_world:8000;
                break;
            }
        }

        location /static/ {
           alias /static/;
           types { text/css css; }
        }
    }
}
```

###### Создаём файл docker-compose.yml
```yaml
version: "3.9"
services:
  db:
    image: postgres:latest
    container_name: postgres          # имя по которому будет отображаться в docker ps
    volumes:
      - pg_data:/var/lib/postgresql/data
    env_file:
      - .env
    ports:
      - "5432:5432"       # порт хоста : порт контейнера

  hello_world:
    build:
      context: ./hello_world        # путь к dockerfile              
    container_name: hello_world
    restart: always
    depends_on:  
      - db
    volumes:
      - ./hello_world:/code
      - static_volume:/code/static
    env_file:
      - .env
    ports:
      - "8000:8000"        # порт хоста : порт контейнера

  nginx:
    image: nginx:latest
    container_name: nginx
    restart: always
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - static_volume:/static
    ports:
      - "80:80"             # порт хоста : порт контейнера
    depends_on:                                  
      - hello_world                        


volumes:
  pg_data:
  static_volume:
```

###### Запускаем локально
В директории с `docker-compose.yml` выполняем команду
```bash
docker-compose up -d               # -d означает как демон(в фоне)
docker-compose down                # остановить
docker-compose logs -f             # логи
```

Посмотреть все выполняющиеся контейнеры
```bash
docker ps
```

Зайти в контейнер с проектом
```bash
docker exec -it music_site /bin/bash
```

Посмотреть ресуры потребляемые контейнером
```bash
docker stats 21462746a7cc
```

###### Выгрузка своего образа в DockerHub

```bash
docker-compose build                        # сбилдить образ используя docker-compose.yml
docker image tag d583c3ac45fd myname/server:latest # переименовать образ
docker build -t ufodriver007/hello_world .  # сбилдить образ используя Dockerfile в текущей
                                            # директории и указать имя hello_world
docker push ufodriver007/hello_world        # запушить образ в DockerHub
docker pull ufodriver007/hello_world        # скачать образ из DockerHub
docker run ufodriver007/hello_world         # запустить скачанный образ
```

