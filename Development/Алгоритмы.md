>[!info] Нотация «O большое» — это математическое обозначение, описывающее, как по мере роста n возрастают требования алгоритма к времени или объему памяти (Время выполнения алгоритма описывается РОСТОМ количества операций.)  О большое — верхняя граница.

==Временная сложность== — это максимальное количество элеметарных шагов, проделываемых алгоритмом для решения задачи. ОЦЕНКА СЛОЖНОСТИ ОПРЕДЕЛЯЕТСЯ ПО ХУДШЕМУ СЦЕНАРИЮ

==Пространственная сложность== —  зависимость количества занимаемой памяти от размера входных данных.

#### Категории сложности алгоритмов(от самого медленного к быстрому)
(n - кол-во ОПЕРАЦИЙ)

|Сложность|Описание|
|-----------|------------|
|O(N!)|факториальная
|O(2ⁿ)|экспоненциальная
|O(N²)|квадоатичная
|O(N * log N)|линейно-логарифмическая
|O(N)|линейная
|O(log N)|логарифмическая
|O(1)|константная

![[BigO.png]]

#### Логарифмы
>[!info] Логарифмы здесь (log) всегда указываются по основанию 2

>[!info] ЛОГАРИФМ - степень(b), в которую надо возвести основание(n), чтобы получить аргумент(x)
$$logₙx = b$$
**n** *основание *
**x** *аргумент*

## Алгоритмы поиска
#### Линейный поиск(простой перебор)
>[!info] Время выполнения - линейное O(n)

В Python для этого  можно использовать оператор in
Следует рассматривать вариант использования, когда данные не отсортированы

#### Бинарный поиск. На вход получает отсортированную последовательность.
>[!info] Время выполнения -логарифмическое O(Log n)

Делим пополам(в середине - опорный элемент). Смотрим опорный элемент меньше или больше, ищем дальше в соответствующей части. До тех пор, пока опорный элемент не станет равен искомому значению

Максимальное число проверок не более *log x*(по основанию 2, здесь и далее.)
1. Определяются две переменных. Верхняя и нижняя граница. 
2. Каждый раз вычисляется среднее значение (оно округляется в меньшую сторону).Если это среднее значение слишком мало, то нижняя граница обновляется. Если СЗ слишком велико, то обновляется верхняя граница.

```
def binary_search(list, item):
    low = 0
    high = len(list) - 1

    while low <= high:               # пока эта часть не сократится до одного элемента...
        mid = (low + high)           # ...проверяем средний элемент
        guess = list[mid]
        if guess == item:            # если значение найдено
           return mid
        if guess > item:             # много
            high = mid - 1
        else:                        # мало
            low = mid + 1
    return None                      # значение не существует
```
Используют, когда данные отсортированы(и в особенности, когда их много)
В реальных проектах нужно пользоваться функцией bisect_left из модуля bisect
```
from bisect import bisect_left

def binary_search(arr, target):
    index = bisect_left(arr, target)
    if <= len(arr) and arr[index] == target:     # нужно проверить индекс, поскольку bisect_left
        return True                              #   может вернуть индекс, выходящий за
                                                 #   пределы последов.
    return False
```

## Поиск в графах
#### Поиск в глубину (DFS, Depth Fiгst Search),
>[!info] O(V + E) вершины + рёбра

Рекурсивный алгоритм по поиску всех вершин графа или дерева. Обход подразумевает под собой посещение всех вершин графа.

1. Начинаем с вершины графа start.
2. Добавляем текущую вершину в хеш-таблицу, чтобы отметить ее как посещенную.
3. Перебираем соседей текущей вершины.
4. Игнорируем смежные вершины, которые уже были посещены.

```
def dfs(graph, start, visited=None):
    if visited is None:
        visited = set() 
    visited.add(start)
    
    for next in graph[start] - visited: 
        if next in visited:  
            continue
        dfs(graph, next, visited) 
        
    return visited
```
```
graph = {'0': set(['1', '2']),
         '1': set(['0', '3', '4']),
         '2': set(['0']),
         '3': set(['1']),
         '4': set(['2', '3'])}

dfs(graph, '0')
```

#### Поиск в ширину (BFS, Breadth-First Search)
>[!info] O(V + E) вершины + рёбра

Алгоритм для решения задачи поиска кратчайшего пути называется поиском в ширину.
Для создания двухсторонней очереди в Python используется deque()

```
from collections import deque
search_queue = deque()                     # создание новой очереди
search_queue += graph['you']               # все соседи добавляются в очередь поиска(1ый уровень)
searched = []                              # массив для отслеживания уже проверенных.
                                           #  предохраняет от бесконечного цикла

while search_queue:                        # пока очередь не пуста...
   person = search_queue.popleft()         # из очереди извлекается первый человек
   if not person in searched:              # проверяется только в случае, если не был проверен ранее
      if person_is_seller(person):         # проверяем, является ли этот чел продавццом манго
         return True                       # да, это продавец
      else:
         search_queue += graph[person]     # нет, не является. Все друзья этого чела добавляются в
                                           #   очередь поиска
         searched.append(person)           # человек помечается как уже проверенный
return False                               # если дошло сюда, значит в очереди нет продавца манго
```

#### Алгоритм Дейкстры
>[!info] Сложность алгоритма(E - рёбра, V - вершины).
>1.  Если вершины хранятся в простом массиве и для поиска минимума используется алгоритм линейного поиска, временная сложность алгоритма Дейкстры составляет **O(V² + E)**
   2. Если же используется очередь с приоритетами, реализованная на основе двоичной кучи (или на основе set), то мы получаем **O(E log V)**
   3. Если же очередь с приоритетами была реализована на основе кучи Фибоначчи, получается наилучшая оценка сложности **O(V log V + E)**

Поиск кратчайшего пути во взвешенных графах. Алгоритм работает только с ненаправленными ациклическими графами
Этот алгоритм работает только с положительными весами рёбер. Для графов с отрицательными весами необходим алгоритм Беллмана-Форда
1. Найти узел с наименьшей стоимостью (то есть узел, до которого можно
    добраться за минимальное время).
2. Проверить, существует ли более дешевый путь к соседям этого узла,
    и если существует, обновить их стоимости.
3. Повторять, пока это не будет сделано для всех узлов графа.
4. Вычислить итоговый путь

```
nоdе = find_lowest_cost_node (costs)             # Найти узел с наименьшей стоимостью среди
                                                 #  необработанных

while node is not None :                         # Если обработаны все узлы, цикл while завершён
   cost = costs[node]
   neighbors = graph[node]
   for n in neighbors.keys():                    # Перебрать всех соседей текущего узла
      new_cost = cost + neighbors[n] 
      if costs[n] > new_cost:                    # Если к соседу можно быстрее добоаться через
                                                 #   текущий узел...
         costs[n] = new_cost                     #...обновить стоимость для этого узла
         parents[n] = node                       # Этот узел становится новым родителем для соседа
   processed.append(node)                        # Узел помечается как обработанный
   node = find_lowest_cost_node(costs)           # Найти следующий узел для обработки и повторить
                                                 #  цикл

def find_lowestcost_node(costs):
   lowest_cost = float("inf")
   lowest_cost_node = None
   for node in costs:                            # Перебрать все узлы
      cost = costs[node]
      if cost < lowest_cost and not in processed: # Если это узел с наименьшей стоимостью из уже
                                                  #   виденных и он ещё не был обработан...
         lowest_cost = cost                      #...он назначается новым узлом с наимеьшей
                                                 #   стоимостью
         lowest_cost_node = node
   return lowest_cost_node

```

## Алгоритмы сортировки
#### Пузырьковая сортировка
>[!info] Время выполнения - квадратичное O(n²)

Сортировка массива по возрастанию. Начинаем с начала и движемся к концу. Сравниваем два стоящих рядом значения(0 и 1).
 1. Если второе значение меньше первого - переставляем. 
 2. Переходим к следующей паре - индексам 1 и 2. Опять сравниваем.
 3. Если второе значение меньше первого - переставляем, и так до конца массива. В конце массива оказалось минимальное значение.
 4. Повторяем так столько раз, сколько элементов в массиве.

```
def bubble_sort(nums):
    # Устанавливаем swapped в True, чтобы цикл запустился хотя бы один раз 
    swapped = True 
    
    while swapped:
        swapped = False
        for i in range(len(nums) - 1):
            if nums[i] > nums[i + 1]:
            
                # Меняем элементы
                nums[i], nums[i + 1] = nums[i + 1], nums[i]
                
                # Устанавливаем swapped в True для следующей итерации 
                swapped = True
```
 
Использование эффективно для малого набора данных, хотя её мало используют на практике(поскольку O(n²)).

#### Сортировка выбором
>[!info]  Время выполнения - квадратичное O(n²)

Сортировка массива по возрастанию. Находим в цикле минимальное значение и ставим его на первое место. Затем ищем минимальное значение начиная со 2го индекса и ставим его на 2е место. Затем ищем начиная с 3го и т.д.

```
def find_smallest(arr)
    smallest = arr[0]               # Для хранения наименьшего значения
    smallest_index = 0              # Для хранения индекса наименьшего значения
    for i in range(1, len(arr)):
        if arr[i] < smallest:
            smallest = arr[i]
            smallest_index = i
    return smallest_index

# На основе этой функции можно написать функцию сортировки выбором

def section_sort(arr):                # сортирует массив
    newAr = []
    for i in range(len(arr)):
        smallest = find_smallest(arr)        # Находит наименьший элемент в массиве
        newArr.append(arr.pop(smallest))    # и добавляет его в новый массив
    return newArr
```

#### Сортировка вставками
>[!info]  Время выполнения - квадратичное O(n²)

Алгоритм сегментирует список на две части: отсортированную и неотсортированную. Алгоритм перебирает второй сегмент и вставляет текущий элемент в правильную позицию первого сегмента.

1. Первое значение считается отсортированным, начинают со второго. 
2. Второе меньше? Ставим второе в начало(первые два теперь отсортировваны). 
3. Проверяем третье, если меньше второго, сравниваем с первым и т.д.

```
def insertion_sort(nums):
    # Сортировку начинаем со второго элемента, т.к. считается, что первый элемент уже отсортирован
    for i in range(1, len(nums)):
        item_to_insert = nums[i] 
        
        # Сохраняем ссылку на индекс предыдущего элемента 
        j = i - 1 
        
        # Элементы отсортированного сегмента перемещаем вперёд, если они больше 
        # элемента для вставки 
        while j >= 0 and nums[j] > item_to_insert: 
            nums[j + 1] = nums[j] j -= 1 
            
        # Вставляем элемент 
        nums[j + 1] = item_to_insert
```

Использование может быть эффективно, когда данные почти отсортированы

#### Быстрая сортировка
>[!info]  Время выполнения - линейно-логарифмическое время O(N * log N) среднее. В худшем случае выбора опорной точки O(n²). Существует параллельная версия быстрой сортировки, которая сортирует массив за время О(n)

На практике этот алгоритм является одним из самых быстрых.

1. На очередном шаге выбирается опорный элемент — им может быть любой элемент массива.
2. Все остальные элементы массива сравниваются с опорным и те, которые меньше него, ставятся слева от него, а которые больше или равны — справа.
3. Для двух получившихся блоков массива (меньше опорного, и больше либо равны опорному) производится точно такая же операция — выделяется опорный элемент и всё идёт точно так же, пока в блоке не останется один элемент.

```
def quicksort(array):
   if len(array) < 2:                             #Базовый случай
      return array                                #массивы с 0 и 1 элементом уже "отсортированы"
   else:
      pivot = array[0]                                #Рекурсивный случай
      less = [i for i in array[1:] if i <= pivot]     #Подмассив всех элементов, меньше опорного
      greater = [i for i in array[1:] if i > pivot]   #Подмассив всех элементов, больше опорного
      return quicksort(less) + [pivot] + quicksort(greater)  
```

#### Сортировка слиянием
>[!info]  Время выполнения - линейно-логарифмическое время O(N * log N)

==Сортировка слиянием== — алгоритм рекурсивной сортировки, который непрерывно разделяет список пополам, пока не найдет один и более списков, содержащих один элемент, а затем соединяет их обратно в правильном порядке. Один из наиболее эффективных алгоритмов сортировки, который широко применяется.
В Python функции *sort* и *sorted* - это гибридная реализация(сочетание сортировки слиянием и сортировки вставками), TimSort.

```
def merge(left_list, right_list):  
    sorted_list = []
    left_list_index = right_list_index = 0

    # Длина списков часто используется, поэтому создадим переменные для удобства
    left_list_length, right_list_length = len(left_list), len(right_list)

    for _ in range(left_list_length + right_list_length):
        if left_list_index < left_list_length and right_list_index < right_list_length:
            # Сравниваем первые элементы в начале каждого списка
            # Если первый элемент левого подсписка меньше, добавляем его
            # в отсортированный массив
            if left_list[left_list_index] <= right_list[right_list_index]:
                sorted_list.append(left_list[left_list_index])
                left_list_index += 1
            # Если первый элемент правого подсписка меньше, добавляем его
            # в отсортированный массив
            else:
                sorted_list.append(right_list[right_list_index])
                right_list_index += 1

        # Если достигнут конец левого списка, элементы правого списка
        # добавляем в конец результирующего списка
        elif left_list_index == left_list_length:
            sorted_list.append(right_list[right_list_index])
            right_list_index += 1
        # Если достигнут конец правого списка, элементы левого списка
        # добавляем в отсортированный массив
        elif right_list_index == right_list_length:
            sorted_list.append(left_list[left_list_index])
            left_list_index += 1

    return sorted_list

def merge_sort(nums):  
    # Возвращаем список, если он состоит из одного элемента
    if len(nums) <= 1:
        return nums

    # Для того чтобы найти середину списка, используем деление без остатка
    # Индексы должны быть integer
    mid = len(nums) // 2

    # Сортируем и объединяем подсписки
    left_list = merge_sort(nums[:mid])
    right_list = merge_sort(nums[mid:])

    # Объединяем отсортированные списки в результирующий
    return merge(left_list, right_list)
```

`merge_sort()`, в отличие от предыдущих алгоритмов, возвращает новый список, а не сортирует существующий. Поэтому такая сортировка требует больше памяти.

#### Пирамидальная сортировка
>[!info]  Время выполнения - линейно-логарифмическое время O(N * log N)

Также известна как сортировка кучей. Этот популярный алгоритм сегментирует список на две части: отсортированную и неотсортированную. Алгоритм преобразует второй сегмент списка в структуру данных «куча» (heap), чтобы можно было эффективно определить самый большой элемент.

1. Сначала преобразуем список в Max Heap — бинарное дерево, где самый большой элемент является вершиной дерева.
2. Помещаем этот элемент в конец списка. 
3. Перестраиваем Max Heap и снова помещаем новый наибольший элемент уже перед последним элементом в списке
4. Этот процесс построения кучи повторяется, пока все вершины дерева не будут удалены.

```
def heapify(nums, heap_size, root_index):  
    # Индекс наибольшего элемента считаем корневым индексом
    largest = root_index
    left_child = (2 * root_index) + 1
    right_child = (2 * root_index) + 2

    # Если левый потомок корня — допустимый индекс, а элемент больше,
    # чем текущий наибольший, обновляем наибольший элемент
    if left_child < heap_size and nums[left_child] > nums[largest]:
        largest = left_child

    # То же самое для правого потомка корня
    if right_child < heap_size and nums[right_child] > nums[largest]:
        largest = right_child

    # Если наибольший элемент больше не корневой, они меняются местами
    if largest != root_index:
        nums[root_index], nums[largest] = nums[largest], nums[root_index]
        # Heapify the new root element to ensure it's the largest
        heapify(nums, heap_size, largest)

def heap_sort(nums):  
    n = len(nums)

    # Создаём Max Heap из списка
    # Второй аргумент означает остановку алгоритма перед элементом -1, т.е.
    # перед первым элементом списка
    # 3-й аргумент означает повторный проход по списку в обратном направлении, 
    # уменьшая счётчик i на 1 
    for i in range(n, -1, -1):
        heapify(nums, n, i)

    # Перемещаем корень Max Heap в конец списка
    for i in range(n - 1, 0, -1):
        nums[i], nums[0] = nums[0], nums[i]
        heapify(nums, i, 0)
```

#### TimSort
>[!info]  Время выполнения(худшее и среднее) - линейно-логарифмическое время O(N * log N). Лучшее время выполнения O(n).

- Алгоритм был изобретен в 2002 году Тимом Петерсом. Стандартный алгоритм сортировки в Python.
- Алгоритм построен на той идее, что в реальном мире сортируемый массив данных часто содержат в себе упорядоченные (не важно, по возрастанию или по убыванию) подмассивы.
- Является гибридом сортировки вставками и слиянием

1. По специальному алгоритму разделяем входной массив на подмассивы.
2. Сортируем каждый подмассив обычной сортировкой вставками.
3. Собираем отсортированные подмассивы в единый массив с помощью модифицированной сортировки слиянием.

## Жадные алгоритмы
>[!info] Жадный алгоритм на каждом шаге выбирает то, что представляется лучшим вариантом в данный момент.

Пример вычисления максимального значения в списке O(n)
```
def max(array):
    maximum = array[0]
    for i in array:
        if i > maximum:
            maximum = i
            
    return maximum
```

## Оптимизация алгоритмов
1. Определение текущей эффективности.
2. Определение лучшей эффективности из возможных.
3. Оптимизация поиска(например использвание хэш-таблицы).
4. Выявление закономерностей(например визуализируя множество примеров).
5. Рассмотрение возможности использования жадных алгоритмов.
6. Замена структуры данных.